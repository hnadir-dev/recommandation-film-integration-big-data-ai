{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "SparkSession.builder.config(conf=SparkConf())\n",
    "\n",
    "import logging\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "#SparkConf.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "es_header = [{\n",
    "'host': 'https://hn-search-9858436033.us-east-1.bonsaisearch.net',\n",
    "'port': 443,\n",
    "'use_ssl': True,\n",
    "'http_auth': (\"i1gd3mbo4r\",\"sf8q52fulp\")\n",
    "}]\n",
    "\n",
    "client = Elasticsearch(\n",
    "        ['https://hn-search-9858436033.us-east-1.bonsaisearch.net:443'],\n",
    "        http_auth=(\"t2mABiEPJn\",\"KwyXmSUap5AMfcR34Lvi\"))\n",
    "\n",
    "\n",
    "def create_spark_configuration():\n",
    "    spark_config = None\n",
    "\n",
    "    try:\n",
    "        spark_config = (SparkSession.builder\n",
    "            .appName(\"ElasticsearchSparkIntegration\")\n",
    "            .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-20_2.12:7.13.4\")#7.17.14\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "            .getOrCreate())\n",
    "        \n",
    "        logging.info(\"Spark connection created successfully!\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Couldn't create the spark session due to exception {e}\")\n",
    "\n",
    "    return spark_config\n",
    "\n",
    "spark = create_spark_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openFile(file_path, mode='r'):\n",
    "    try:\n",
    "        return open(file_path, mode)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise\n",
    "\n",
    "def getDataframeFromFile(filed):\n",
    "    data = []\n",
    "    #\n",
    "    while True:\n",
    "\n",
    "        line = filed.readline()\n",
    "\n",
    "        # if line is empty\n",
    "        if line.strip() == \"\":\n",
    "            break\n",
    "\n",
    "        rec = line.strip().split('|')\n",
    "        \n",
    "        item = {}\n",
    "\n",
    "        if len(rec) > 6:\n",
    "            item['movieId'] = rec[0]\n",
    "            item['name'] = rec[1]\n",
    "            item['release_date'] = rec[2]\n",
    "            item['url'] = rec[4]\n",
    "\n",
    "            #5 => 23\n",
    "            item['genre'] = [genre[idx]['name'] for  idx, g in enumerate(range(5,24)) if rec[g] == '1']\n",
    "\n",
    "        elif len(rec) == 2:\n",
    "            item['id'] = rec[1]\n",
    "            item['name'] = rec[0]\n",
    "            \n",
    "        elif len(rec) == 5:\n",
    "            item['userId'] = rec[0]\n",
    "            item['age'] = rec[1]\n",
    "            item['gender'] = rec[2]\n",
    "            item['function'] = rec[3]\n",
    "        else:\n",
    "            print(\"Invalid record format. Skipping.\")\n",
    "            return\n",
    "\n",
    "        data.append(item)\n",
    "    filed.close()\n",
    "    return data\n",
    "\n",
    "def getDataframe(filed):\n",
    "    data = []\n",
    "    while True:\n",
    "        line = filed.readline()\n",
    "        # if line is empty\n",
    "        if line.strip() == \"\":\n",
    "            break\n",
    "\n",
    "        rec = line.strip().split('\\t')\n",
    "\n",
    "        item = {}\n",
    "        item['userId'] = rec[0]\n",
    "        item['movieId'] = rec[1]\n",
    "        item['rating'] = rec[2]\n",
    "        item['timestamp'] = rec[3]\n",
    "        data.append(item)\n",
    "    filed.close()\n",
    "    return data\n",
    "\n",
    "#=>Data\n",
    "fileGenre = openFile('../data/u.genre')\n",
    "fileItem = openFile('../data/u.item')\n",
    "fileUser = openFile('../data/u.user')\n",
    "fileData = openFile('../data/u.data')\n",
    "\n",
    "df_relationship_data = pd.DataFrame(getDataframe(fileData))\n",
    "\n",
    "genre = getDataframeFromFile(fileGenre)\n",
    "items = getDataframeFromFile(fileItem)\n",
    "users = getDataframeFromFile(fileUser)\n",
    "\n",
    "df_movies = pd.DataFrame(items)\n",
    "df_users = pd.DataFrame(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\BigDataSetup\\Spark\\spark-3.2.4-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\conversion.py:329: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 1.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n",
      "C:\\BigDataSetup\\Spark\\spark-3.2.4-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, age: string, gender: string, function: string]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_users = spark.createDataFrame(df_users)\n",
    "\n",
    "def create_selection_df_from_users_df(spark_df):\n",
    "    schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), False),\n",
    "        StructField(\"adult\", BooleanType(), False),\n",
    "        StructField(\"backdrop_path\", StringType(), False),\n",
    "        StructField(\"genre_ids\", ArrayType(IntegerType()), False),\n",
    "        StructField(\"original_language\", StringType(), False),\n",
    "        StructField(\"original_title\", StringType(), False),\n",
    "        StructField(\"overview\", StringType(), False),\n",
    "        StructField(\"popularity\", DoubleType(), False),\n",
    "        StructField(\"poster_path\", StringType(), False),\n",
    "        StructField(\"release_date\", StringType(), False),\n",
    "        StructField(\"title\", StringType(), False),\n",
    "        StructField(\"video\", BooleanType(), False),\n",
    "        StructField(\"vote_average\", DoubleType(), False),\n",
    "        StructField(\"vote_count\", IntegerType(), False)\n",
    "    ])\n",
    "\n",
    "    sel = (spark_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "        .select(from_json(col('value'), schema).alias('data')).select(\"data.*\") \\\n",
    "        .withColumn(\"description\", concat(col('title'),lit(' : '),col('overview'))) \\\n",
    "        .withColumn('popularity',col(\"popularity\").cast('double')) \\\n",
    "        .withColumn('vote_average',col(\"vote_average\").cast('double')) \\\n",
    "        .withColumn('release_date',to_date(col('release_date'),\"yyyy-MM-dd\")) \\\n",
    "        .select('id','adult','genre_ids','original_language','original_title','description','popularity','release_date','video','vote_average','vote_count','backdrop_path','poster_path'))\n",
    "\n",
    "    return sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user in df_users.itertuples():\n",
    "#     client.index(index='users-index',body={\n",
    "#         'userId':user.userId,\n",
    "#         'age':user.age,\n",
    "#         'gender':user.gender,\n",
    "#         'function':user.function\n",
    "#     },id=user.userId)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
